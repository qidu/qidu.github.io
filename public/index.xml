<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Abstract of an AI Agent Age</title>
    <link>http://localhost:1313/public/</link>
    <description>Recent content on Abstract of an AI Agent Age</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 30 Jul 2025 10:50:26 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/public/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Forget Her and Remember Memento, the Nolan Movie</title>
      <link>http://localhost:1313/public/posts/forget-her-and-remember-memento-of-nolan-movie/</link>
      <pubDate>Wed, 30 Jul 2025 10:50:26 +0800</pubDate>
      <guid>http://localhost:1313/public/posts/forget-her-and-remember-memento-of-nolan-movie/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;Forget &amp;ldquo;Her&amp;rdquo;, Nolan&amp;rsquo;s old movie &amp;ldquo;Memento&amp;rdquo; maybe is a compulsory course for LLM Agents.&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;In Last year(2024), from Chatbot to Voice Agent demo, &amp;ldquo;Intention recognition&amp;rdquo; and &amp;ldquo;Multi-round dialogue&amp;rdquo; are expected as the key capabilities&#xA;of an idea AGI system.&lt;/p&gt;&#xA;&lt;p&gt;But in this year(2025), Agents can &amp;ldquo;think&amp;rdquo; and &amp;ldquo;act&amp;rdquo; for a goal by tasks breaking down, tools calling and self planning are invented and used more in reality life, and especially in programing works.&lt;/p&gt;</description>
    </item>
    <item>
      <title>What Is Context Engineering</title>
      <link>http://localhost:1313/public/posts/what-is-context-engineering/</link>
      <pubDate>Tue, 15 Jul 2025 14:23:41 +0800</pubDate>
      <guid>http://localhost:1313/public/posts/what-is-context-engineering/</guid>
      <description>&lt;p&gt;What is the Context?&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;Instructions&lt;/code&gt; / &lt;code&gt;System Prompt&lt;/code&gt;: An initial set of instructions that define the behavior of the model during a conversation, can/should include examples, rules ….&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;User Prompt&lt;/code&gt;: Immediate task or question from the user.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;State / History&lt;/code&gt; (short-term Memory): The current conversation, including user and model responses that have led to this moment.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;Long-Term Memory&lt;/code&gt;: Persistent knowledge base, gathered across many prior conversations, containing learned user preferences, summaries of past projects, or facts it has been told to remember for future use.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;Retrieved Information (RAG)&lt;/code&gt;: External, up-to-date knowledge, relevant information from documents, databases, or APIs to answer specific questions.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;Available Tools&lt;/code&gt;: Definitions of all the functions or built-in tools it can call (e.g., check_inventory, send_email).&#xA;Structured Output: Definitions on the format of the model&amp;rsquo;s response, e.g. a JSON object.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Why context engineering matters for agent?&lt;/p&gt;</description>
    </item>
    <item>
      <title>A2a Is Hosted by Linux Foundation</title>
      <link>http://localhost:1313/public/posts/a2a-is-hosted-by-linux-foundation/</link>
      <pubDate>Tue, 24 Jun 2025 14:12:51 +0800</pubDate>
      <guid>http://localhost:1313/public/posts/a2a-is-hosted-by-linux-foundation/</guid>
      <description>&lt;p&gt;The A2A(Agent2Agent) protocol addresses the growing need for agents to operate in dynamic, multi-agent environments, coordinating actions across a wide array of applications and data infrastructure. A2A enables autonomous agents to discover one another, exchange information securely and collaborate across systems. This allows developers and organizations to unite agents from multiple sources and platforms, improving modularity, mitigating vendor lock-in and accelerating innovation.&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;The protocol enables agentic AI interoperability and trusted agent communication across systems and platforms.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Just Look at What AI Can Do</title>
      <link>http://localhost:1313/public/posts/just-look-at-what-ai-can-do/</link>
      <pubDate>Mon, 09 Jun 2025 15:18:51 +0800</pubDate>
      <guid>http://localhost:1313/public/posts/just-look-at-what-ai-can-do/</guid>
      <description>&lt;p&gt;“What&amp;rsquo;s the next best step? And I find that whenever I do this myself, everything works out so much better. But it&amp;rsquo;s hard. It&amp;rsquo;s hard. It&amp;rsquo;s a constant struggle with one&amp;rsquo;s emotion. And that&amp;rsquo;s why I mention it to you. Perhaps some of you will adopt it yourself. This is a reminder to adopt this mindset as best as one can. And also a reminder for myself. &amp;quot;&lt;/p&gt;&#xA;&lt;p&gt;&amp;ldquo;There is something a little different going on right now. Anything which I can learn, anything which any one of you can learn, the AI could do as well. How do we know this, by the way? How can I be so sure? The reason is that all of us have a brain, and the brain is a biological computer. That&amp;rsquo;s why we have a brain.&amp;rdquo;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Are the Softwares Ending by Agents?</title>
      <link>http://localhost:1313/public/posts/the-softwares-are-ending-by-agents/</link>
      <pubDate>Thu, 05 Jun 2025 16:49:48 +0800</pubDate>
      <guid>http://localhost:1313/public/posts/the-softwares-are-ending-by-agents/</guid>
      <description>&lt;p&gt;Will we experience a &lt;code&gt;Cambrian explosion&lt;/code&gt; of software, the same way we did with content?&lt;/p&gt;&#xA;&lt;h2 id=&#34;storyline&#34;&gt;Storyline&lt;/h2&gt;&#xA;&lt;h3 id=&#34;before-the-internet&#34;&gt;Before the internet&lt;/h3&gt;&#xA;&lt;p&gt;Media behaved very differently —— it was expensive to create. You had to pay people to make content, edit it, and distribute it. Because content was expensive to create, it had to make money. And consumers paid —— newspapers, magazines, books, cable, and pay per view.&lt;/p&gt;&#xA;&lt;h3 id=&#34;when-the-internet-happened&#34;&gt;When the internet happened&lt;/h3&gt;&#xA;&lt;p&gt;The Media companies viewed it as a way to reach broader audiences and reduce their distribution costs. But what no one saw coming was that the internet not only reduced distribution costs to zero, but it also drove the cost of creating content to zero.&#xA;User generated content flourished, and when content doesn’t cost anything to create, it no longer has to make money.&lt;/p&gt;</description>
    </item>
    <item>
      <title>What Is an Agent?</title>
      <link>http://localhost:1313/public/posts/what-is-an-agent/</link>
      <pubDate>Tue, 27 May 2025 22:44:03 +0800</pubDate>
      <guid>http://localhost:1313/public/posts/what-is-an-agent/</guid>
      <description>&lt;p&gt;Agent is&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;a “term so overused to mean so many different things that&lt;/li&gt;&#xA;&lt;li&gt;it starts to lose any real meaning in conversation&lt;/li&gt;&#xA;&lt;li&gt;because everyone is confidently using it to refer to different things”&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;in 2025.&lt;/p&gt;&#xA;&lt;p&gt;What we talk about when we talk about Agent?&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;When we talking about AI agents with someone and are either&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;(a) not really sure what an agent is and how it is different from the generative AI capabilities we’ve seen so far,&lt;/li&gt;&#xA;&lt;li&gt;(b) not really sure the person using the term knows what an agent is, or&lt;/li&gt;&#xA;&lt;li&gt;(c) might have thought that they knew what an agent is until reading the first sentence of this article.&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;We could refer to &lt;a href=&#34;https://windsurf.com/blog/what-is-an-agent&#34;&gt;Windsurf&amp;rsquo;s Agent&lt;/a&gt; article to make some theoretical concepts more tractable.&lt;/p&gt;</description>
    </item>
    <item>
      <title>From Function Calling to MCP, to A2A</title>
      <link>http://localhost:1313/public/posts/from-function-calling-to-mcp-to-a2a/</link>
      <pubDate>Fri, 23 May 2025 12:10:44 +0800</pubDate>
      <guid>http://localhost:1313/public/posts/from-function-calling-to-mcp-to-a2a/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://google-a2a.github.io/A2A/assets/a2a-mcp-readme.png&#34; alt=&#34;Agentic Application uses A2A to communicate, uses MCP for tools calling&#34; title=&#34;A2A and MCP&#34;&gt;&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://google.github.io/A2A/topics/a2a-and-mcp&#34;&gt;A2A and MCP&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;An A2A Server (a remote agent) could also expose some of its skills as MCP-compatible resources, especially if those skills are well-defined and can be invoked in a more tool-like.&lt;/li&gt;&#xA;&lt;li&gt;Other agent might &amp;ldquo;discover&amp;rdquo; this A2A agent&amp;rsquo;s specific skill via an MCP-style tool description (from its Agent Card).&lt;/li&gt;&#xA;&lt;li&gt;A2A is about agents partnering on tasks, while MCP is more about agents using capabilities.&lt;/li&gt;&#xA;&lt;li&gt;A2A for inter-agent collaboration and MCP for tool integration.&lt;/li&gt;&#xA;&lt;li&gt;A2A facilitates the higher-level, conversational, and task-oriented interactions between partners.&lt;/li&gt;&#xA;&lt;li&gt;MCP enables some agents to use specific, structured tools to perform specific functions.&lt;/li&gt;&#xA;&lt;/ul&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://google.github.io/A2A/assets/a2a-mcp-readme.png&#34; alt=&#34;A2A and MCP: Complementary Protocols&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>An Agent Development Kit</title>
      <link>http://localhost:1313/public/posts/an-agent-development-kit/</link>
      <pubDate>Thu, 22 May 2025 14:52:35 +0800</pubDate>
      <guid>http://localhost:1313/public/posts/an-agent-development-kit/</guid>
      <description>&lt;p&gt;&lt;code&gt;An Agent Development Kit&lt;/code&gt;&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;code&gt;adk&lt;/code&gt; represents as dev tool for Agent, not for Android.&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;workflow-agents-for-coding&#34;&gt;Workflow Agents for coding&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Code Writer Agent&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Takes the initial specification (from user query) and writes code.&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;code_writer_agent &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; LlmAgent(&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;CodeWriterAgent&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    model&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;LiteLlm(model&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;custom_openai/deepseek-v3-0324&amp;#34;&lt;/span&gt;),&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;Code Reviewer Agent&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;Review Criteria:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Correctness:&lt;/strong&gt; Does the code work as intended? Are there logic errors?&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Readability:&lt;/strong&gt; Is the code clear and easy to understand? Follows PEP 8 style guidelines?&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Efficiency:&lt;/strong&gt; Is the code reasonably efficient? Any obvious performance bottlenecks?&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Edge Cases:&lt;/strong&gt; Does the code handle potential edge cases or invalid inputs gracefully?&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Best Practices:&lt;/strong&gt; Does the code follow common Python best practices?&lt;/li&gt;&#xA;&lt;/ol&gt;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Takes the code generated by the previous agent (read from state) and provides feedback.&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;code_reviewer_agent &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; LlmAgent(&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;CodeReviewerAgent&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    model&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;LiteLlm(model&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;deepseek/deepseek-chat&amp;#34;&lt;/span&gt;),&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;Code Refactorer Agent&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Takes the original code and the review comments (read from state) and refactors the code.&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;code_refactorer_agent &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; LlmAgent(&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    name&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;CodeRefactorerAgent&amp;#34;&lt;/span&gt;,&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    model&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;LiteLlm(model&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;custom_openai/deepseek-r1&amp;#34;&lt;/span&gt;),&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;SequentialAgent runs pipline: Writer -&amp;gt; Reviewer -&amp;gt; Refactorer&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;code_pipeline_agent = SequentialAgent(&#xA;    name=&amp;#34;CodePipelineAgent&amp;#34;,&#xA;    sub_agents=[code_writer_agent, code_reviewer_agent, code_refactorer_agent],&#xA;    description=(&#xA;        &amp;#34;Executes a sequence of code writing, reviewing, and refactoring.&amp;#34;&#xA;    ),&#xA;)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then run the agent&lt;/p&gt;</description>
    </item>
    <item>
      <title>MoA: Mixture of Agents</title>
      <link>http://localhost:1313/public/posts/moa-mixture-of-agents/</link>
      <pubDate>Wed, 14 May 2025 19:34:20 +0800</pubDate>
      <guid>http://localhost:1313/public/posts/moa-mixture-of-agents/</guid>
      <description>&lt;p&gt;&lt;code&gt;The proposed MoA architecture&lt;/code&gt;&lt;/p&gt;&#xA;&lt;p&gt;The proposed architecture contains two main components: the proposers and the aggregators, both of which are LLMs that excel in their respective aspect of collaboration. for example GPT-4o, Qwen1.5, LLaMA-3 emerged as a versatile model effective in both assisting and aggregating tasks. In contrast, &lt;code&gt;WizardLM&lt;/code&gt; demonstrated excellent performance as a proposer model but struggled to maintain its effectiveness in aggregating responses from other models.&lt;/p&gt;&#xA;&lt;p&gt;learn more at:&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Agent War: Competition With Different Methodology</title>
      <link>http://localhost:1313/public/posts/the-agent-war-competition-with-different-methodology/</link>
      <pubDate>Wed, 14 May 2025 10:48:52 +0800</pubDate>
      <guid>http://localhost:1313/public/posts/the-agent-war-competition-with-different-methodology/</guid>
      <description>&lt;p&gt;&lt;code&gt;Distinct approaches to implementing Agentic AI&lt;/code&gt;:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Microsoft adopts a &amp;ldquo;Universal Platform&amp;rdquo; strategy, aiming to build an &lt;code&gt;AI operating system&lt;/code&gt; that reshapes the software ecosystem by overhauling its underlying architecture. Its Agents act as cross-system intelligent hubs, replacing traditional databases and business logic, shifting from an &amp;ldquo;App Stack&amp;rdquo; to an &amp;ldquo;Agent Stack&amp;rdquo;.&lt;/li&gt;&#xA;&lt;li&gt;Salesforce follows a &amp;ldquo;Vertical Integration&amp;rdquo; approach, embedding Agents deeply into &lt;code&gt;CRM and specific workflows&lt;/code&gt; within its existing SaaS business, enhancing task autonomy without disrupting the current architecture.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;code&gt;Key Differences&lt;/code&gt;:&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Starting Point for the Agent</title>
      <link>http://localhost:1313/public/posts/the-starting-point-for-the-agent/</link>
      <pubDate>Tue, 13 May 2025 19:16:50 +0800</pubDate>
      <guid>http://localhost:1313/public/posts/the-starting-point-for-the-agent/</guid>
      <description>&lt;p&gt;Building agents with LLM is implemented much more into reality from a cool concept.&#xA;Planning, Tool Calling, Acting, Self-Reflection are the standard 4 steps of the Agent Architecture,&#xA;or the Agentic AI now.&lt;/p&gt;&#xA;&lt;p&gt;We can learn more from the starting point for the Agent in this article:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://lilianweng.github.io/posts/2023-06-23-agent/&#34;&gt;LLM Powered Autonomous Agents&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
  </channel>
</rss>
