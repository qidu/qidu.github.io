<!DOCTYPE html>
<html lang="en-us">
  <head><script src="/public/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=public/livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Nondeterminism, Hallucinate and Context Rot of Llm | Abstract of an AI Agent Age</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="Nondeterminism, Hallucinate and Context Rot

Some new understandings of LLM that relate to Agent and Tools-calling
How does batch inference influence the output?
refer to
Defeating Nondeterminism in LLM Inference
Why llm output hallucination?
refer to
Why language models hallucinate
Does longer input context result in a better output?
refer to
Context Rot: How Increasing Input Tokens Impacts LLM Performance">
    <meta name="generator" content="Hugo 0.147.3">
    
    
    
      <meta name="robots" content="noindex, nofollow">
    
    

    
<link rel="stylesheet" href="/public/ananke/css/main.min.css" >




    


    
      

    

    

    
      <link rel="canonical" href="http://localhost:1313/public/posts/nondeterminism-hallucinate-and-context-rot-of-llm/">
    

    <meta property="og:url" content="http://localhost:1313/public/posts/nondeterminism-hallucinate-and-context-rot-of-llm/">
  <meta property="og:site_name" content="Abstract of an AI Agent Age">
  <meta property="og:title" content="Nondeterminism, Hallucinate and Context Rot of Llm">
  <meta property="og:description" content="Nondeterminism, Hallucinate and Context Rot
Some new understandings of LLM that relate to Agent and Tools-calling
How does batch inference influence the output? refer to Defeating Nondeterminism in LLM Inference
Why llm output hallucination? refer to Why language models hallucinate
Does longer input context result in a better output? refer to Context Rot: How Increasing Input Tokens Impacts LLM Performance">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-09-11T17:38:12+08:00">
    <meta property="article:modified_time" content="2025-09-11T17:38:12+08:00">

  <meta itemprop="name" content="Nondeterminism, Hallucinate and Context Rot of Llm">
  <meta itemprop="description" content="Nondeterminism, Hallucinate and Context Rot
Some new understandings of LLM that relate to Agent and Tools-calling
How does batch inference influence the output? refer to Defeating Nondeterminism in LLM Inference
Why llm output hallucination? refer to Why language models hallucinate
Does longer input context result in a better output? refer to Context Rot: How Increasing Input Tokens Impacts LLM Performance">
  <meta itemprop="datePublished" content="2025-09-11T17:38:12+08:00">
  <meta itemprop="dateModified" content="2025-09-11T17:38:12+08:00">
  <meta itemprop="wordCount" content="60">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Nondeterminism, Hallucinate and Context Rot of Llm">
  <meta name="twitter:description" content="Nondeterminism, Hallucinate and Context Rot
Some new understandings of LLM that relate to Agent and Tools-calling
How does batch inference influence the output? refer to Defeating Nondeterminism in LLM Inference
Why llm output hallucination? refer to Why language models hallucinate
Does longer input context result in a better output? refer to Context Rot: How Increasing Input Tokens Impacts LLM Performance">

	
  </head><body class="ma0 avenir bg-near-white development">

    
   
  

  <header>
    <div class="bg-black">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l center items-center justify-between">
    <a href="/public/" class="f3 fw2 hover-white white-90 dib no-underline">
      
        Abstract of an AI Agent Age
      
    </a>
    <div class="flex-l items-center">
      

      
      <div class="ananke-socials"></div>

    </div>
  </div>
</nav>

    </div>
  </header>



    <main class="pb7" role="main">
      
  
  
  <article class="flex-l mw8 center ph3 flex-wrap justify-between">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked ttu">
          
        Posts
      </aside><div id="sharing" class="mt3 ananke-socials"></div>
<h1 class="f1 athelas mt3 mb1">Nondeterminism, Hallucinate and Context Rot of Llm</h1>
      
      
      
      <time class="f6 mv4 dib tracked" datetime="2025-09-11T17:38:12+08:00">September 11, 2025</time>
      

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links mid-gray pr4-l w-two-thirds-l"><p><code>Nondeterminism, Hallucinate and Context Rot</code></p>
<blockquote>
<p>Some new understandings of LLM that relate to Agent and Tools-calling</p></blockquote>
<p>How does batch inference influence the output?
refer to
<a href="https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/">Defeating Nondeterminism in LLM Inference</a></p>
<p>Why llm output hallucination?
refer to
<a href="https://openai.com/index/why-language-models-hallucinate/">Why language models hallucinate</a></p>
<p>Does longer input context result in a better output?
refer to
<a href="https://research.trychroma.com/context-rot">Context Rot: How Increasing Input Tokens Impacts LLM Performance</a></p>
<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white white-70 dn dib-ns pv2 ph3 no-underline" href="http://localhost:1313/public/" >
    &copy;  Abstract of an AI Agent Age 2025 
  </a>
    <div><div class="ananke-socials"></div>
</div>
  </div>
</footer>

  </body>
</html>
