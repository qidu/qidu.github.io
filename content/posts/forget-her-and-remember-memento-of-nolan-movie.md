+++
date = '2025-07-30T10:50:26+08:00'
draft = false
title = 'Forget Her and Remember Memento, the Nolan Movie'
+++

> Forget "Her", Nolan's old movie "Memento" maybe is a compulsory course for LLM Agents.

In Last year(2024), from Chatbot to Voice Agent demo, "Intention recognition" and "Multi-round dialogue" are expected as the key capabilities 
of an idea AGI system.

But in this year(2025), Agents can "think" and "act" for a goal by tasks breaking down, tools calling and self planning are invented and used more in reality life, and especially in programing works.

> "Her" is still far away, and "He" (Leonard, the key role of 《Memento》) comes true.

Same challenges of "He" (Leonard) and AI Agents: 
> How to execute a stateful system that is inherently stateless and has an extremely limited memory window (or information overload) that requires long-term, statefulness, complex tasks to track?

The solution is building a powerful external system for the "short-term memory" brain or "limited context window" LLM, which we call context engineering today.

Three Pillars of `Context Engineering`:
- No.1 `External Knowledge Management`: Such as Leonard's Polaroid Photos
  - Information Capture: preverve key infos for later needs.
  - Context Annotation: get judgment and insights behind raw data.
  - On-Demand Retrieval: retrive relevant historical knowledge at the precise moments when it needs to make a decision.
- No.2 `Context Distillation & Structuring`: Such as Key notes
  -  Distillation & Compression: distills countless clues and inferences into an unchangeable "assertion".
  - Structuring: ensures that the most important information has the highest "read priority".
- No.3 `Hierarchical Memory Management`: such as Tattoo System
  - Core Mission Layer - Tattoo: The information at this layer is immutable and has the highest decision weight. 
  - Episodic Working Memory - Photos and Notes: This layer is Read/Write, which records the intermediate steps of the task, the obstacles encountered, and the evidence collected.
  - Volatile Processing Window - 15 minutes of brain memory: This corresponds directly to the limited context window of the LLM,  It is where the real "thinking" takes place. 

Leonard's two tragedies, or two "Fatal Loopholes" in Agent's Design: 

- Loophole 1: `External poisoning` - "fed" lies by Officer Teddy
> Note the risk of Context Poisoning, or "Garbage In, Gospel Out" risk.

- Loophole 2: `Internal contamination` - being deceived by your own notes
> This reveals a more hidden vulnerability than the External Poisoning: the `Self-Reinforcing Cognitive Prison`.

Conclusion: Agent needs `Verification & Reflection` module
The agent system needs to have a mechanism to compare the gap between the results of the action and the expected goal, generate an "error report", and use this report as a key context input for the next action. 


Refer more from:

[Forget "Her", Nolan's old movie "Memento" is a compulsory course for LLM Agents](https://mp.weixin.qq.com/s/0D6fd1etd_nkiDTkRdTnmw) (Note: It is an article co-writed with AI chatbot.)


