+++
date = '2025-09-11T17:38:12+08:00'
draft = false
title = 'Nondeterminism, Hallucinate and Context Rot of Llm'
+++

`Nondeterminism, Hallucinate and Context Rot`
> Some new understandings of LLM that relate to Agent and Tools-calling

How does batch inference influence the output? 
refer to 
[Defeating Nondeterminism in LLM Inference](https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/)

Why llm output hallucination? 
refer to
[Why language models hallucinate](https://openai.com/index/why-language-models-hallucinate/)

Does longer input context result in a better output? 
refer to
[Context Rot: How Increasing Input Tokens Impacts LLM Performance](https://research.trychroma.com/context-rot)
